{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLEARML_WEB_HOST=https://app.clear.ml\n",
      "env: CLEARML_API_HOST=https://api.clear.ml\n",
      "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
      "env: CLEARML_API_ACCESS_KEY=ROEW1HL5Z947HSWMOE1M\n",
      "env: CLEARML_API_SECRET_KEY=wym7QpDMcGgyGAS2NIHBq53TL6djugqJB5gNgdOUXS1HUtHTYP\n"
     ]
    }
   ],
   "source": [
    "%env CLEARML_WEB_HOST=https://app.clear.ml\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=ROEW1HL5Z947HSWMOE1M\n",
    "%env CLEARML_API_SECRET_KEY=wym7QpDMcGgyGAS2NIHBq53TL6djugqJB5gNgdOUXS1HUtHTYP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: overwriting (reusing) task id=5c5a863934154973ac9b3ed0e0a9255b\n",
      "2024-04-30 15:07:54,048 - clearml.Repository Detection - WARNING - Could not read Jupyter Notebook: No module named 'nbconvert'\n",
      "2024-04-30 15:07:54,071 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.clear.ml/projects/bda991b03ff34114b2ef93fc1e8d32ba/experiments/5c5a863934154973ac9b3ed0e0a9255b/output/log\n"
     ]
    }
   ],
   "source": [
    "from clearml import Task\n",
    "\n",
    "# Step 1: Creating a ClearML Task\n",
    "task = Task.init(\n",
    "    project_name=\"drons_vs_berds\",\n",
    "    task_name=\"detection2\"\n",
    ")\n",
    "logger = task.get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(\"/home/vlad/datasets/drons_vs_berds/images/2019_10_16_C0003_5043_mavic/0002.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/30 13:30:52 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/anaconda3/envs/berds_vs_drons/lib/python3.11/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2.imwrite('./img.jpg', out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"my_dataset_train\", {}, \"/home/vlad/datasets/drons_vs_berds/coco/dataset/drons_vs_berds_train.json\", \"/home/vlad/datasets/drons_vs_berds/images\")\n",
    "register_coco_instances(\"my_dataset_val\", {}, \"/home/vlad/datasets/drons_vs_berds/coco/dataset/drons_vs_berds_valid.json\", \"/home/vlad/datasets/drons_vs_berds/images\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(\"my_dataset_test\", {}, \"/home/vlad/datasets/drons_vs_berds/coco/dataset/drons_vs_berds_test.json\", \"/home/vlad/datasets/drons_vs_berds/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import detection_utils as utils\n",
    "import detectron2.data.transforms as T\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "def custom_mapper(dataset_dict):\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n",
    "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "    transform_list = [\n",
    "        T.Resize((1024,1024)),\n",
    "        T.RandomBrightness(0.8, 1.8),\n",
    "        T.RandomContrast(0.6, 1.3),\n",
    "        T.RandomSaturation(0.8, 1.4),\n",
    "        T.RandomRotation(angle=[45, 45]),\n",
    "        T.RandomLighting(0.7),\n",
    "        T.RandomFlip(prob=0.4, horizontal=False, vertical=True),\n",
    "    ]\n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
    "\n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop(\"annotations\")\n",
    "        if obj.get(\"iscrowd\", 0) == 0\n",
    "    ]\n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "    return dataset_dict\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "import torch\n",
    "from detectron2.solver.build import get_default_optimizer_params\n",
    "from detectron2.solver.build import maybe_add_gradient_clipping\n",
    "\n",
    "class CustomTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=custom_mapper)\n",
    "    \n",
    "    # https://medium.com/innovation-res/detectron2-config-optimizer-lr-scheduler-part-1-4555842e1ea\n",
    "    @classmethod\n",
    "    def build_optimizer(cls, cfg, model):\n",
    "        \"\"\"\n",
    "        Build an optimizer from config.\n",
    "        \"\"\"\n",
    "        params = get_default_optimizer_params(model)\n",
    "        return maybe_add_gradient_clipping(cfg, torch.optim.AdamW)(\n",
    "                          params, \n",
    "                          lr=cfg.SOLVER.BASE_LR,        \n",
    "                          weight_decay=cfg.SOLVER.WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/30 15:08:15 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[04/30 15:08:16 d2.data.datasets.coco]: \u001b[0mLoaded 41632 images in COCO format from /home/vlad/datasets/drons_vs_berds/coco/dataset/drons_vs_berds_train.json\n",
      "\u001b[32m[04/30 15:08:16 d2.data.build]: \u001b[0mRemoved 3557 images with no usable annotations. 38075 images left.\n",
      "\u001b[32m[04/30 15:08:16 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   drone    | 48136        |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[04/30 15:08:16 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[04/30 15:08:16 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/30 15:08:16 d2.data.common]: \u001b[0mSerializing 38075 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 15:08:16 d2.data.common]: \u001b[0mSerialized dataset takes 10.12 MiB\n",
      "\u001b[32m[04/30 15:08:16 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=3\n",
      "\u001b[32m[04/30 15:08:16 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)  \n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\")  # Let training initialize from model zoo\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 3  \n",
    "cfg.SOLVER.MAX_ITER = 1000\n",
    "cfg.SOLVER.BASE_LR = 8e-4\n",
    "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"\n",
    "cfg.SOLVER.WARMUP_ITERS = int(0.2*cfg.SOLVER.MAX_ITER)\n",
    "\n",
    "# cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "# cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "# cfg.SOLVER.MAX_ITER = 200    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "# cfg.SOLVER.STEPS = (100, 200)        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "# cfg.INPUT.MIN_SIZE_TRAIN= 800\n",
    "# cfg.INPUT.MAX_SIZE_TRAIN=  1024\n",
    "# cfg.INPUT.MIN_SIZE_TEST=  800\n",
    "# cfg.INPUT.MAX_SIZE_TEST= 1024\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = CustomTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/30 15:08:24 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output/model_final.pth ...\n",
      "2024-04-30 15:08:26,642 - clearml.model - INFO - Selected model id: ff725052627041a5bc94681af9fd900f\n"
     ]
    }
   ],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/30 17:35:01 d2.data.datasets.coco]: \u001b[0mLoaded 7805 images in COCO format from /home/vlad/datasets/drons_vs_berds/coco/dataset/drons_vs_berds_valid.json\n",
      "\u001b[32m[04/30 17:35:01 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   drone    | 7068         |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[04/30 17:35:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/30 17:35:01 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/30 17:35:01 d2.data.common]: \u001b[0mSerializing 7805 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 17:35:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.92 MiB\n",
      "\u001b[32m[04/30 17:35:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 7805 batches\n",
      "\u001b[32m[04/30 17:35:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/7805. Dataloading: 0.0011 s/iter. Inference: 0.0890 s/iter. Eval: 0.0001 s/iter. Total: 0.0902 s/iter. ETA=0:11:43\n",
      "\u001b[32m[04/30 17:35:08 d2.evaluation.evaluator]: \u001b[0mInference done 64/7805. Dataloading: 0.0021 s/iter. Inference: 0.0923 s/iter. Eval: 0.0001 s/iter. Total: 0.0946 s/iter. ETA=0:12:12\n",
      "\u001b[32m[04/30 17:35:13 d2.evaluation.evaluator]: \u001b[0mInference done 120/7805. Dataloading: 0.0016 s/iter. Inference: 0.0903 s/iter. Eval: 0.0001 s/iter. Total: 0.0921 s/iter. ETA=0:11:47\n",
      "\u001b[32m[04/30 17:35:18 d2.evaluation.evaluator]: \u001b[0mInference done 178/7805. Dataloading: 0.0014 s/iter. Inference: 0.0890 s/iter. Eval: 0.0001 s/iter. Total: 0.0905 s/iter. ETA=0:11:30\n",
      "\u001b[32m[04/30 17:35:23 d2.evaluation.evaluator]: \u001b[0mInference done 235/7805. Dataloading: 0.0015 s/iter. Inference: 0.0886 s/iter. Eval: 0.0001 s/iter. Total: 0.0902 s/iter. ETA=0:11:22\n",
      "\u001b[32m[04/30 17:35:28 d2.evaluation.evaluator]: \u001b[0mInference done 286/7805. Dataloading: 0.0033 s/iter. Inference: 0.0883 s/iter. Eval: 0.0001 s/iter. Total: 0.0918 s/iter. ETA=0:11:30\n",
      "\u001b[32m[04/30 17:35:33 d2.evaluation.evaluator]: \u001b[0mInference done 348/7805. Dataloading: 0.0028 s/iter. Inference: 0.0869 s/iter. Eval: 0.0001 s/iter. Total: 0.0900 s/iter. ETA=0:11:10\n",
      "\u001b[32m[04/30 17:35:38 d2.evaluation.evaluator]: \u001b[0mInference done 414/7805. Dataloading: 0.0025 s/iter. Inference: 0.0851 s/iter. Eval: 0.0001 s/iter. Total: 0.0878 s/iter. ETA=0:10:49\n",
      "\u001b[32m[04/30 17:35:43 d2.evaluation.evaluator]: \u001b[0mInference done 482/7805. Dataloading: 0.0023 s/iter. Inference: 0.0834 s/iter. Eval: 0.0001 s/iter. Total: 0.0858 s/iter. ETA=0:10:28\n",
      "\u001b[32m[04/30 17:35:48 d2.evaluation.evaluator]: \u001b[0mInference done 553/7805. Dataloading: 0.0021 s/iter. Inference: 0.0817 s/iter. Eval: 0.0001 s/iter. Total: 0.0840 s/iter. ETA=0:10:08\n",
      "\u001b[32m[04/30 17:35:53 d2.evaluation.evaluator]: \u001b[0mInference done 619/7805. Dataloading: 0.0020 s/iter. Inference: 0.0810 s/iter. Eval: 0.0001 s/iter. Total: 0.0831 s/iter. ETA=0:09:57\n",
      "\u001b[32m[04/30 17:35:58 d2.evaluation.evaluator]: \u001b[0mInference done 689/7805. Dataloading: 0.0019 s/iter. Inference: 0.0800 s/iter. Eval: 0.0001 s/iter. Total: 0.0820 s/iter. ETA=0:09:43\n",
      "\u001b[32m[04/30 17:36:03 d2.evaluation.evaluator]: \u001b[0mInference done 760/7805. Dataloading: 0.0018 s/iter. Inference: 0.0790 s/iter. Eval: 0.0001 s/iter. Total: 0.0810 s/iter. ETA=0:09:30\n",
      "\u001b[32m[04/30 17:36:08 d2.evaluation.evaluator]: \u001b[0mInference done 831/7805. Dataloading: 0.0017 s/iter. Inference: 0.0783 s/iter. Eval: 0.0001 s/iter. Total: 0.0801 s/iter. ETA=0:09:18\n",
      "\u001b[32m[04/30 17:36:13 d2.evaluation.evaluator]: \u001b[0mInference done 902/7805. Dataloading: 0.0016 s/iter. Inference: 0.0776 s/iter. Eval: 0.0001 s/iter. Total: 0.0794 s/iter. ETA=0:09:08\n",
      "\u001b[32m[04/30 17:36:18 d2.evaluation.evaluator]: \u001b[0mInference done 973/7805. Dataloading: 0.0015 s/iter. Inference: 0.0771 s/iter. Eval: 0.0001 s/iter. Total: 0.0788 s/iter. ETA=0:08:58\n",
      "\u001b[32m[04/30 17:36:23 d2.evaluation.evaluator]: \u001b[0mInference done 1044/7805. Dataloading: 0.0015 s/iter. Inference: 0.0766 s/iter. Eval: 0.0001 s/iter. Total: 0.0783 s/iter. ETA=0:08:49\n",
      "\u001b[32m[04/30 17:36:28 d2.evaluation.evaluator]: \u001b[0mInference done 1114/7805. Dataloading: 0.0015 s/iter. Inference: 0.0763 s/iter. Eval: 0.0001 s/iter. Total: 0.0779 s/iter. ETA=0:08:41\n",
      "\u001b[32m[04/30 17:36:33 d2.evaluation.evaluator]: \u001b[0mInference done 1184/7805. Dataloading: 0.0014 s/iter. Inference: 0.0759 s/iter. Eval: 0.0001 s/iter. Total: 0.0775 s/iter. ETA=0:08:33\n",
      "\u001b[32m[04/30 17:36:38 d2.evaluation.evaluator]: \u001b[0mInference done 1254/7805. Dataloading: 0.0014 s/iter. Inference: 0.0756 s/iter. Eval: 0.0001 s/iter. Total: 0.0772 s/iter. ETA=0:08:25\n",
      "\u001b[32m[04/30 17:36:44 d2.evaluation.evaluator]: \u001b[0mInference done 1325/7805. Dataloading: 0.0013 s/iter. Inference: 0.0754 s/iter. Eval: 0.0001 s/iter. Total: 0.0769 s/iter. ETA=0:08:18\n",
      "\u001b[32m[04/30 17:36:49 d2.evaluation.evaluator]: \u001b[0mInference done 1395/7805. Dataloading: 0.0013 s/iter. Inference: 0.0751 s/iter. Eval: 0.0001 s/iter. Total: 0.0766 s/iter. ETA=0:08:11\n",
      "\u001b[32m[04/30 17:36:54 d2.evaluation.evaluator]: \u001b[0mInference done 1462/7805. Dataloading: 0.0013 s/iter. Inference: 0.0751 s/iter. Eval: 0.0001 s/iter. Total: 0.0766 s/iter. ETA=0:08:05\n",
      "\u001b[32m[04/30 17:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 1531/7805. Dataloading: 0.0013 s/iter. Inference: 0.0750 s/iter. Eval: 0.0001 s/iter. Total: 0.0764 s/iter. ETA=0:07:59\n",
      "\u001b[32m[04/30 17:37:04 d2.evaluation.evaluator]: \u001b[0mInference done 1600/7805. Dataloading: 0.0013 s/iter. Inference: 0.0748 s/iter. Eval: 0.0001 s/iter. Total: 0.0762 s/iter. ETA=0:07:53\n",
      "\u001b[32m[04/30 17:37:09 d2.evaluation.evaluator]: \u001b[0mInference done 1663/7805. Dataloading: 0.0012 s/iter. Inference: 0.0750 s/iter. Eval: 0.0001 s/iter. Total: 0.0764 s/iter. ETA=0:07:49\n",
      "\u001b[32m[04/30 17:37:14 d2.evaluation.evaluator]: \u001b[0mInference done 1727/7805. Dataloading: 0.0012 s/iter. Inference: 0.0751 s/iter. Eval: 0.0001 s/iter. Total: 0.0765 s/iter. ETA=0:07:44\n",
      "\u001b[32m[04/30 17:37:19 d2.evaluation.evaluator]: \u001b[0mInference done 1787/7805. Dataloading: 0.0012 s/iter. Inference: 0.0754 s/iter. Eval: 0.0001 s/iter. Total: 0.0767 s/iter. ETA=0:07:41\n",
      "\u001b[32m[04/30 17:37:24 d2.evaluation.evaluator]: \u001b[0mInference done 1847/7805. Dataloading: 0.0012 s/iter. Inference: 0.0756 s/iter. Eval: 0.0001 s/iter. Total: 0.0770 s/iter. ETA=0:07:38\n",
      "\u001b[32m[04/30 17:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 1913/7805. Dataloading: 0.0012 s/iter. Inference: 0.0756 s/iter. Eval: 0.0001 s/iter. Total: 0.0769 s/iter. ETA=0:07:33\n",
      "\u001b[32m[04/30 17:37:34 d2.evaluation.evaluator]: \u001b[0mInference done 1984/7805. Dataloading: 0.0012 s/iter. Inference: 0.0754 s/iter. Eval: 0.0001 s/iter. Total: 0.0767 s/iter. ETA=0:07:26\n",
      "\u001b[32m[04/30 17:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 2054/7805. Dataloading: 0.0012 s/iter. Inference: 0.0752 s/iter. Eval: 0.0001 s/iter. Total: 0.0765 s/iter. ETA=0:07:20\n",
      "\u001b[32m[04/30 17:37:44 d2.evaluation.evaluator]: \u001b[0mInference done 2124/7805. Dataloading: 0.0012 s/iter. Inference: 0.0751 s/iter. Eval: 0.0001 s/iter. Total: 0.0764 s/iter. ETA=0:07:13\n",
      "\u001b[32m[04/30 17:37:49 d2.evaluation.evaluator]: \u001b[0mInference done 2207/7805. Dataloading: 0.0011 s/iter. Inference: 0.0745 s/iter. Eval: 0.0001 s/iter. Total: 0.0758 s/iter. ETA=0:07:04\n",
      "\u001b[32m[04/30 17:37:54 d2.evaluation.evaluator]: \u001b[0mInference done 2292/7805. Dataloading: 0.0011 s/iter. Inference: 0.0739 s/iter. Eval: 0.0001 s/iter. Total: 0.0752 s/iter. ETA=0:06:54\n",
      "\u001b[32m[04/30 17:37:59 d2.evaluation.evaluator]: \u001b[0mInference done 2377/7805. Dataloading: 0.0011 s/iter. Inference: 0.0733 s/iter. Eval: 0.0001 s/iter. Total: 0.0746 s/iter. ETA=0:06:44\n",
      "\u001b[32m[04/30 17:38:04 d2.evaluation.evaluator]: \u001b[0mInference done 2462/7805. Dataloading: 0.0011 s/iter. Inference: 0.0728 s/iter. Eval: 0.0001 s/iter. Total: 0.0741 s/iter. ETA=0:06:35\n",
      "\u001b[32m[04/30 17:38:09 d2.evaluation.evaluator]: \u001b[0mInference done 2540/7805. Dataloading: 0.0011 s/iter. Inference: 0.0725 s/iter. Eval: 0.0001 s/iter. Total: 0.0738 s/iter. ETA=0:06:28\n",
      "\u001b[32m[04/30 17:38:14 d2.evaluation.evaluator]: \u001b[0mInference done 2623/7805. Dataloading: 0.0011 s/iter. Inference: 0.0721 s/iter. Eval: 0.0001 s/iter. Total: 0.0734 s/iter. ETA=0:06:20\n",
      "\u001b[32m[04/30 17:38:19 d2.evaluation.evaluator]: \u001b[0mInference done 2708/7805. Dataloading: 0.0011 s/iter. Inference: 0.0717 s/iter. Eval: 0.0001 s/iter. Total: 0.0729 s/iter. ETA=0:06:11\n",
      "\u001b[32m[04/30 17:38:24 d2.evaluation.evaluator]: \u001b[0mInference done 2789/7805. Dataloading: 0.0011 s/iter. Inference: 0.0714 s/iter. Eval: 0.0001 s/iter. Total: 0.0726 s/iter. ETA=0:06:04\n",
      "\u001b[32m[04/30 17:38:29 d2.evaluation.evaluator]: \u001b[0mInference done 2874/7805. Dataloading: 0.0011 s/iter. Inference: 0.0710 s/iter. Eval: 0.0001 s/iter. Total: 0.0722 s/iter. ETA=0:05:56\n",
      "\u001b[32m[04/30 17:38:34 d2.evaluation.evaluator]: \u001b[0mInference done 2946/7805. Dataloading: 0.0011 s/iter. Inference: 0.0710 s/iter. Eval: 0.0001 s/iter. Total: 0.0722 s/iter. ETA=0:05:50\n",
      "\u001b[32m[04/30 17:38:39 d2.evaluation.evaluator]: \u001b[0mInference done 3017/7805. Dataloading: 0.0011 s/iter. Inference: 0.0710 s/iter. Eval: 0.0001 s/iter. Total: 0.0721 s/iter. ETA=0:05:45\n",
      "\u001b[32m[04/30 17:38:44 d2.evaluation.evaluator]: \u001b[0mInference done 3087/7805. Dataloading: 0.0011 s/iter. Inference: 0.0709 s/iter. Eval: 0.0001 s/iter. Total: 0.0721 s/iter. ETA=0:05:40\n",
      "\u001b[32m[04/30 17:38:49 d2.evaluation.evaluator]: \u001b[0mInference done 3152/7805. Dataloading: 0.0010 s/iter. Inference: 0.0711 s/iter. Eval: 0.0001 s/iter. Total: 0.0723 s/iter. ETA=0:05:36\n",
      "\u001b[32m[04/30 17:38:54 d2.evaluation.evaluator]: \u001b[0mInference done 3221/7805. Dataloading: 0.0010 s/iter. Inference: 0.0711 s/iter. Eval: 0.0001 s/iter. Total: 0.0723 s/iter. ETA=0:05:31\n",
      "\u001b[32m[04/30 17:39:00 d2.evaluation.evaluator]: \u001b[0mInference done 3288/7805. Dataloading: 0.0010 s/iter. Inference: 0.0712 s/iter. Eval: 0.0001 s/iter. Total: 0.0723 s/iter. ETA=0:05:26\n",
      "\u001b[32m[04/30 17:39:05 d2.evaluation.evaluator]: \u001b[0mInference done 3356/7805. Dataloading: 0.0010 s/iter. Inference: 0.0712 s/iter. Eval: 0.0001 s/iter. Total: 0.0724 s/iter. ETA=0:05:22\n",
      "\u001b[32m[04/30 17:39:10 d2.evaluation.evaluator]: \u001b[0mInference done 3423/7805. Dataloading: 0.0010 s/iter. Inference: 0.0713 s/iter. Eval: 0.0001 s/iter. Total: 0.0724 s/iter. ETA=0:05:17\n",
      "\u001b[32m[04/30 17:39:15 d2.evaluation.evaluator]: \u001b[0mInference done 3490/7805. Dataloading: 0.0010 s/iter. Inference: 0.0713 s/iter. Eval: 0.0001 s/iter. Total: 0.0725 s/iter. ETA=0:05:12\n",
      "\u001b[32m[04/30 17:39:20 d2.evaluation.evaluator]: \u001b[0mInference done 3557/7805. Dataloading: 0.0010 s/iter. Inference: 0.0714 s/iter. Eval: 0.0001 s/iter. Total: 0.0725 s/iter. ETA=0:05:08\n",
      "\u001b[32m[04/30 17:39:25 d2.evaluation.evaluator]: \u001b[0mInference done 3626/7805. Dataloading: 0.0010 s/iter. Inference: 0.0714 s/iter. Eval: 0.0001 s/iter. Total: 0.0725 s/iter. ETA=0:05:03\n",
      "\u001b[32m[04/30 17:39:30 d2.evaluation.evaluator]: \u001b[0mInference done 3693/7805. Dataloading: 0.0010 s/iter. Inference: 0.0714 s/iter. Eval: 0.0001 s/iter. Total: 0.0726 s/iter. ETA=0:04:58\n",
      "\u001b[32m[04/30 17:39:35 d2.evaluation.evaluator]: \u001b[0mInference done 3761/7805. Dataloading: 0.0010 s/iter. Inference: 0.0715 s/iter. Eval: 0.0001 s/iter. Total: 0.0726 s/iter. ETA=0:04:53\n",
      "\u001b[32m[04/30 17:39:40 d2.evaluation.evaluator]: \u001b[0mInference done 3826/7805. Dataloading: 0.0010 s/iter. Inference: 0.0715 s/iter. Eval: 0.0001 s/iter. Total: 0.0727 s/iter. ETA=0:04:49\n",
      "\u001b[32m[04/30 17:39:45 d2.evaluation.evaluator]: \u001b[0mInference done 3892/7805. Dataloading: 0.0010 s/iter. Inference: 0.0716 s/iter. Eval: 0.0001 s/iter. Total: 0.0728 s/iter. ETA=0:04:44\n",
      "\u001b[32m[04/30 17:39:50 d2.evaluation.evaluator]: \u001b[0mInference done 3959/7805. Dataloading: 0.0010 s/iter. Inference: 0.0716 s/iter. Eval: 0.0001 s/iter. Total: 0.0728 s/iter. ETA=0:04:39\n",
      "\u001b[32m[04/30 17:39:55 d2.evaluation.evaluator]: \u001b[0mInference done 4028/7805. Dataloading: 0.0010 s/iter. Inference: 0.0717 s/iter. Eval: 0.0001 s/iter. Total: 0.0728 s/iter. ETA=0:04:34\n",
      "\u001b[32m[04/30 17:40:00 d2.evaluation.evaluator]: \u001b[0mInference done 4090/7805. Dataloading: 0.0010 s/iter. Inference: 0.0718 s/iter. Eval: 0.0001 s/iter. Total: 0.0729 s/iter. ETA=0:04:30\n",
      "\u001b[32m[04/30 17:40:05 d2.evaluation.evaluator]: \u001b[0mInference done 4145/7805. Dataloading: 0.0010 s/iter. Inference: 0.0720 s/iter. Eval: 0.0001 s/iter. Total: 0.0732 s/iter. ETA=0:04:27\n",
      "\u001b[32m[04/30 17:40:10 d2.evaluation.evaluator]: \u001b[0mInference done 4199/7805. Dataloading: 0.0010 s/iter. Inference: 0.0723 s/iter. Eval: 0.0001 s/iter. Total: 0.0734 s/iter. ETA=0:04:24\n",
      "\u001b[32m[04/30 17:40:15 d2.evaluation.evaluator]: \u001b[0mInference done 4261/7805. Dataloading: 0.0010 s/iter. Inference: 0.0724 s/iter. Eval: 0.0001 s/iter. Total: 0.0735 s/iter. ETA=0:04:20\n",
      "\u001b[32m[04/30 17:40:20 d2.evaluation.evaluator]: \u001b[0mInference done 4329/7805. Dataloading: 0.0010 s/iter. Inference: 0.0724 s/iter. Eval: 0.0001 s/iter. Total: 0.0735 s/iter. ETA=0:04:15\n",
      "\u001b[32m[04/30 17:40:25 d2.evaluation.evaluator]: \u001b[0mInference done 4392/7805. Dataloading: 0.0010 s/iter. Inference: 0.0725 s/iter. Eval: 0.0001 s/iter. Total: 0.0736 s/iter. ETA=0:04:11\n",
      "\u001b[32m[04/30 17:40:30 d2.evaluation.evaluator]: \u001b[0mInference done 4458/7805. Dataloading: 0.0010 s/iter. Inference: 0.0725 s/iter. Eval: 0.0001 s/iter. Total: 0.0737 s/iter. ETA=0:04:06\n",
      "\u001b[32m[04/30 17:40:35 d2.evaluation.evaluator]: \u001b[0mInference done 4518/7805. Dataloading: 0.0011 s/iter. Inference: 0.0726 s/iter. Eval: 0.0001 s/iter. Total: 0.0738 s/iter. ETA=0:04:02\n",
      "\u001b[32m[04/30 17:40:40 d2.evaluation.evaluator]: \u001b[0mInference done 4580/7805. Dataloading: 0.0012 s/iter. Inference: 0.0726 s/iter. Eval: 0.0001 s/iter. Total: 0.0739 s/iter. ETA=0:03:58\n",
      "\u001b[32m[04/30 17:40:45 d2.evaluation.evaluator]: \u001b[0mInference done 4643/7805. Dataloading: 0.0012 s/iter. Inference: 0.0727 s/iter. Eval: 0.0001 s/iter. Total: 0.0740 s/iter. ETA=0:03:53\n",
      "\u001b[32m[04/30 17:40:50 d2.evaluation.evaluator]: \u001b[0mInference done 4706/7805. Dataloading: 0.0012 s/iter. Inference: 0.0727 s/iter. Eval: 0.0001 s/iter. Total: 0.0741 s/iter. ETA=0:03:49\n",
      "\u001b[32m[04/30 17:40:55 d2.evaluation.evaluator]: \u001b[0mInference done 4768/7805. Dataloading: 0.0012 s/iter. Inference: 0.0728 s/iter. Eval: 0.0001 s/iter. Total: 0.0742 s/iter. ETA=0:03:45\n",
      "\u001b[32m[04/30 17:41:00 d2.evaluation.evaluator]: \u001b[0mInference done 4832/7805. Dataloading: 0.0012 s/iter. Inference: 0.0729 s/iter. Eval: 0.0001 s/iter. Total: 0.0742 s/iter. ETA=0:03:40\n",
      "\u001b[32m[04/30 17:41:05 d2.evaluation.evaluator]: \u001b[0mInference done 4896/7805. Dataloading: 0.0012 s/iter. Inference: 0.0730 s/iter. Eval: 0.0001 s/iter. Total: 0.0743 s/iter. ETA=0:03:36\n",
      "\u001b[32m[04/30 17:41:10 d2.evaluation.evaluator]: \u001b[0mInference done 4961/7805. Dataloading: 0.0012 s/iter. Inference: 0.0730 s/iter. Eval: 0.0001 s/iter. Total: 0.0743 s/iter. ETA=0:03:31\n",
      "\u001b[32m[04/30 17:41:15 d2.evaluation.evaluator]: \u001b[0mInference done 5028/7805. Dataloading: 0.0012 s/iter. Inference: 0.0730 s/iter. Eval: 0.0001 s/iter. Total: 0.0743 s/iter. ETA=0:03:26\n",
      "\u001b[32m[04/30 17:41:20 d2.evaluation.evaluator]: \u001b[0mInference done 5095/7805. Dataloading: 0.0012 s/iter. Inference: 0.0730 s/iter. Eval: 0.0001 s/iter. Total: 0.0743 s/iter. ETA=0:03:21\n",
      "\u001b[32m[04/30 17:41:25 d2.evaluation.evaluator]: \u001b[0mInference done 5161/7805. Dataloading: 0.0011 s/iter. Inference: 0.0731 s/iter. Eval: 0.0001 s/iter. Total: 0.0744 s/iter. ETA=0:03:16\n",
      "\u001b[32m[04/30 17:41:30 d2.evaluation.evaluator]: \u001b[0mInference done 5222/7805. Dataloading: 0.0011 s/iter. Inference: 0.0732 s/iter. Eval: 0.0001 s/iter. Total: 0.0745 s/iter. ETA=0:03:12\n",
      "\u001b[32m[04/30 17:41:35 d2.evaluation.evaluator]: \u001b[0mInference done 5284/7805. Dataloading: 0.0011 s/iter. Inference: 0.0732 s/iter. Eval: 0.0001 s/iter. Total: 0.0745 s/iter. ETA=0:03:07\n",
      "\u001b[32m[04/30 17:41:41 d2.evaluation.evaluator]: \u001b[0mInference done 5352/7805. Dataloading: 0.0011 s/iter. Inference: 0.0732 s/iter. Eval: 0.0001 s/iter. Total: 0.0745 s/iter. ETA=0:03:02\n",
      "\u001b[32m[04/30 17:41:46 d2.evaluation.evaluator]: \u001b[0mInference done 5418/7805. Dataloading: 0.0011 s/iter. Inference: 0.0733 s/iter. Eval: 0.0001 s/iter. Total: 0.0745 s/iter. ETA=0:02:57\n",
      "\u001b[32m[04/30 17:41:51 d2.evaluation.evaluator]: \u001b[0mInference done 5489/7805. Dataloading: 0.0011 s/iter. Inference: 0.0732 s/iter. Eval: 0.0001 s/iter. Total: 0.0745 s/iter. ETA=0:02:52\n",
      "\u001b[32m[04/30 17:41:56 d2.evaluation.evaluator]: \u001b[0mInference done 5559/7805. Dataloading: 0.0011 s/iter. Inference: 0.0732 s/iter. Eval: 0.0001 s/iter. Total: 0.0745 s/iter. ETA=0:02:47\n",
      "\u001b[32m[04/30 17:42:01 d2.evaluation.evaluator]: \u001b[0mInference done 5629/7805. Dataloading: 0.0011 s/iter. Inference: 0.0732 s/iter. Eval: 0.0001 s/iter. Total: 0.0744 s/iter. ETA=0:02:41\n",
      "\u001b[32m[04/30 17:42:06 d2.evaluation.evaluator]: \u001b[0mInference done 5695/7805. Dataloading: 0.0011 s/iter. Inference: 0.0732 s/iter. Eval: 0.0001 s/iter. Total: 0.0745 s/iter. ETA=0:02:37\n",
      "\u001b[32m[04/30 17:42:11 d2.evaluation.evaluator]: \u001b[0mInference done 5762/7805. Dataloading: 0.0011 s/iter. Inference: 0.0732 s/iter. Eval: 0.0001 s/iter. Total: 0.0745 s/iter. ETA=0:02:32\n",
      "\u001b[32m[04/30 17:42:16 d2.evaluation.evaluator]: \u001b[0mInference done 5832/7805. Dataloading: 0.0011 s/iter. Inference: 0.0732 s/iter. Eval: 0.0001 s/iter. Total: 0.0744 s/iter. ETA=0:02:26\n",
      "\u001b[32m[04/30 17:42:21 d2.evaluation.evaluator]: \u001b[0mInference done 5902/7805. Dataloading: 0.0011 s/iter. Inference: 0.0731 s/iter. Eval: 0.0001 s/iter. Total: 0.0744 s/iter. ETA=0:02:21\n",
      "\u001b[32m[04/30 17:42:26 d2.evaluation.evaluator]: \u001b[0mInference done 5971/7805. Dataloading: 0.0011 s/iter. Inference: 0.0731 s/iter. Eval: 0.0001 s/iter. Total: 0.0744 s/iter. ETA=0:02:16\n",
      "\u001b[32m[04/30 17:42:31 d2.evaluation.evaluator]: \u001b[0mInference done 6039/7805. Dataloading: 0.0011 s/iter. Inference: 0.0731 s/iter. Eval: 0.0001 s/iter. Total: 0.0744 s/iter. ETA=0:02:11\n",
      "\u001b[32m[04/30 17:42:36 d2.evaluation.evaluator]: \u001b[0mInference done 6099/7805. Dataloading: 0.0011 s/iter. Inference: 0.0732 s/iter. Eval: 0.0001 s/iter. Total: 0.0745 s/iter. ETA=0:02:07\n",
      "\u001b[32m[04/30 17:42:41 d2.evaluation.evaluator]: \u001b[0mInference done 6165/7805. Dataloading: 0.0011 s/iter. Inference: 0.0732 s/iter. Eval: 0.0001 s/iter. Total: 0.0745 s/iter. ETA=0:02:02\n",
      "\u001b[32m[04/30 17:42:46 d2.evaluation.evaluator]: \u001b[0mInference done 6235/7805. Dataloading: 0.0011 s/iter. Inference: 0.0732 s/iter. Eval: 0.0001 s/iter. Total: 0.0745 s/iter. ETA=0:01:56\n",
      "\u001b[32m[04/30 17:42:51 d2.evaluation.evaluator]: \u001b[0mInference done 6300/7805. Dataloading: 0.0011 s/iter. Inference: 0.0733 s/iter. Eval: 0.0001 s/iter. Total: 0.0745 s/iter. ETA=0:01:52\n",
      "\u001b[32m[04/30 17:42:56 d2.evaluation.evaluator]: \u001b[0mInference done 6377/7805. Dataloading: 0.0011 s/iter. Inference: 0.0732 s/iter. Eval: 0.0001 s/iter. Total: 0.0744 s/iter. ETA=0:01:46\n",
      "\u001b[32m[04/30 17:43:01 d2.evaluation.evaluator]: \u001b[0mInference done 6457/7805. Dataloading: 0.0011 s/iter. Inference: 0.0730 s/iter. Eval: 0.0001 s/iter. Total: 0.0743 s/iter. ETA=0:01:40\n",
      "\u001b[32m[04/30 17:43:06 d2.evaluation.evaluator]: \u001b[0mInference done 6537/7805. Dataloading: 0.0011 s/iter. Inference: 0.0729 s/iter. Eval: 0.0001 s/iter. Total: 0.0741 s/iter. ETA=0:01:33\n",
      "\u001b[32m[04/30 17:43:11 d2.evaluation.evaluator]: \u001b[0mInference done 6612/7805. Dataloading: 0.0011 s/iter. Inference: 0.0728 s/iter. Eval: 0.0001 s/iter. Total: 0.0740 s/iter. ETA=0:01:28\n",
      "\u001b[32m[04/30 17:43:16 d2.evaluation.evaluator]: \u001b[0mInference done 6693/7805. Dataloading: 0.0011 s/iter. Inference: 0.0727 s/iter. Eval: 0.0001 s/iter. Total: 0.0739 s/iter. ETA=0:01:22\n",
      "\u001b[32m[04/30 17:43:21 d2.evaluation.evaluator]: \u001b[0mInference done 6775/7805. Dataloading: 0.0011 s/iter. Inference: 0.0725 s/iter. Eval: 0.0001 s/iter. Total: 0.0737 s/iter. ETA=0:01:15\n",
      "\u001b[32m[04/30 17:43:26 d2.evaluation.evaluator]: \u001b[0mInference done 6858/7805. Dataloading: 0.0011 s/iter. Inference: 0.0724 s/iter. Eval: 0.0001 s/iter. Total: 0.0736 s/iter. ETA=0:01:09\n",
      "\u001b[32m[04/30 17:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 6941/7805. Dataloading: 0.0011 s/iter. Inference: 0.0722 s/iter. Eval: 0.0001 s/iter. Total: 0.0734 s/iter. ETA=0:01:03\n",
      "\u001b[32m[04/30 17:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 7023/7805. Dataloading: 0.0011 s/iter. Inference: 0.0721 s/iter. Eval: 0.0001 s/iter. Total: 0.0733 s/iter. ETA=0:00:57\n",
      "\u001b[32m[04/30 17:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 7092/7805. Dataloading: 0.0011 s/iter. Inference: 0.0721 s/iter. Eval: 0.0001 s/iter. Total: 0.0733 s/iter. ETA=0:00:52\n",
      "\u001b[32m[04/30 17:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 7163/7805. Dataloading: 0.0011 s/iter. Inference: 0.0720 s/iter. Eval: 0.0001 s/iter. Total: 0.0733 s/iter. ETA=0:00:47\n",
      "\u001b[32m[04/30 17:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 7232/7805. Dataloading: 0.0011 s/iter. Inference: 0.0720 s/iter. Eval: 0.0001 s/iter. Total: 0.0733 s/iter. ETA=0:00:41\n",
      "\u001b[32m[04/30 17:43:56 d2.evaluation.evaluator]: \u001b[0mInference done 7306/7805. Dataloading: 0.0011 s/iter. Inference: 0.0720 s/iter. Eval: 0.0001 s/iter. Total: 0.0732 s/iter. ETA=0:00:36\n",
      "\u001b[32m[04/30 17:44:01 d2.evaluation.evaluator]: \u001b[0mInference done 7379/7805. Dataloading: 0.0011 s/iter. Inference: 0.0720 s/iter. Eval: 0.0001 s/iter. Total: 0.0732 s/iter. ETA=0:00:31\n",
      "\u001b[32m[04/30 17:44:06 d2.evaluation.evaluator]: \u001b[0mInference done 7455/7805. Dataloading: 0.0011 s/iter. Inference: 0.0719 s/iter. Eval: 0.0001 s/iter. Total: 0.0731 s/iter. ETA=0:00:25\n",
      "\u001b[32m[04/30 17:44:12 d2.evaluation.evaluator]: \u001b[0mInference done 7534/7805. Dataloading: 0.0011 s/iter. Inference: 0.0718 s/iter. Eval: 0.0001 s/iter. Total: 0.0730 s/iter. ETA=0:00:19\n",
      "\u001b[32m[04/30 17:44:17 d2.evaluation.evaluator]: \u001b[0mInference done 7614/7805. Dataloading: 0.0011 s/iter. Inference: 0.0717 s/iter. Eval: 0.0001 s/iter. Total: 0.0729 s/iter. ETA=0:00:13\n",
      "\u001b[32m[04/30 17:44:22 d2.evaluation.evaluator]: \u001b[0mInference done 7689/7805. Dataloading: 0.0010 s/iter. Inference: 0.0716 s/iter. Eval: 0.0001 s/iter. Total: 0.0728 s/iter. ETA=0:00:08\n",
      "\u001b[32m[04/30 17:44:27 d2.evaluation.evaluator]: \u001b[0mInference done 7768/7805. Dataloading: 0.0010 s/iter. Inference: 0.0715 s/iter. Eval: 0.0001 s/iter. Total: 0.0727 s/iter. ETA=0:00:02\n",
      "\u001b[32m[04/30 17:44:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:09:27.038047 (0.072697 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/30 17:44:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:09:17 (0.071508 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/30 17:44:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 17:44:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[04/30 17:44:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 17:44:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 17:44:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.28 seconds.\n",
      "\u001b[32m[04/30 17:44:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 17:44:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.060\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.054\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.057\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.057\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.049\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
      "\u001b[32m[04/30 17:44:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.978 | 5.984  | 0.007  | 2.663 | 0.719 | 0.011 |\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"my_dataset_val\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_val\")\n",
    " \n",
    "result = inference_on_dataset(predictor.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 4.056669176752632,\n",
       "               'AP50': 19.234785394932196,\n",
       "               'AP75': 0.10334012124616718,\n",
       "               'APs': 4.3205221332592725,\n",
       "               'APm': 5.843446451718537,\n",
       "               'APl': 4.369740454518531})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/07 22:49:04 d2.data.datasets.coco]: \u001b[0mLoaded 3116 images in COCO format from /home/vlad/datasets/drons_vs_berds/coco/dataset/drons_vs_berds_test.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/07 22:49:04 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   drone    | 3729         |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[04/07 22:49:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/07 22:49:04 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/07 22:49:04 d2.data.common]: \u001b[0mSerializing 3116 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/07 22:49:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.81 MiB\n",
      "\u001b[32m[04/07 22:49:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 3116 batches\n",
      "\u001b[32m[04/07 22:49:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/3116. Dataloading: 0.0006 s/iter. Inference: 0.0801 s/iter. Eval: 0.0000 s/iter. Total: 0.0807 s/iter. ETA=0:04:10\n",
      "\u001b[32m[04/07 22:49:10 d2.evaluation.evaluator]: \u001b[0mInference done 73/3116. Dataloading: 0.0008 s/iter. Inference: 0.0798 s/iter. Eval: 0.0000 s/iter. Total: 0.0807 s/iter. ETA=0:04:05\n",
      "\u001b[32m[04/07 22:49:15 d2.evaluation.evaluator]: \u001b[0mInference done 136/3116. Dataloading: 0.0008 s/iter. Inference: 0.0796 s/iter. Eval: 0.0001 s/iter. Total: 0.0805 s/iter. ETA=0:03:59\n",
      "\u001b[32m[04/07 22:49:20 d2.evaluation.evaluator]: \u001b[0mInference done 200/3116. Dataloading: 0.0008 s/iter. Inference: 0.0790 s/iter. Eval: 0.0001 s/iter. Total: 0.0800 s/iter. ETA=0:03:53\n",
      "\u001b[32m[04/07 22:49:25 d2.evaluation.evaluator]: \u001b[0mInference done 268/3116. Dataloading: 0.0008 s/iter. Inference: 0.0774 s/iter. Eval: 0.0001 s/iter. Total: 0.0783 s/iter. ETA=0:03:43\n",
      "\u001b[32m[04/07 22:49:30 d2.evaluation.evaluator]: \u001b[0mInference done 331/3116. Dataloading: 0.0008 s/iter. Inference: 0.0776 s/iter. Eval: 0.0001 s/iter. Total: 0.0785 s/iter. ETA=0:03:38\n",
      "\u001b[32m[04/07 22:49:35 d2.evaluation.evaluator]: \u001b[0mInference done 395/3116. Dataloading: 0.0008 s/iter. Inference: 0.0776 s/iter. Eval: 0.0001 s/iter. Total: 0.0785 s/iter. ETA=0:03:33\n",
      "\u001b[32m[04/07 22:49:40 d2.evaluation.evaluator]: \u001b[0mInference done 459/3116. Dataloading: 0.0008 s/iter. Inference: 0.0776 s/iter. Eval: 0.0001 s/iter. Total: 0.0785 s/iter. ETA=0:03:28\n",
      "\u001b[32m[04/07 22:49:45 d2.evaluation.evaluator]: \u001b[0mInference done 523/3116. Dataloading: 0.0008 s/iter. Inference: 0.0776 s/iter. Eval: 0.0001 s/iter. Total: 0.0786 s/iter. ETA=0:03:23\n",
      "\u001b[32m[04/07 22:49:50 d2.evaluation.evaluator]: \u001b[0mInference done 587/3116. Dataloading: 0.0008 s/iter. Inference: 0.0776 s/iter. Eval: 0.0001 s/iter. Total: 0.0786 s/iter. ETA=0:03:18\n",
      "\u001b[32m[04/07 22:49:55 d2.evaluation.evaluator]: \u001b[0mInference done 652/3116. Dataloading: 0.0008 s/iter. Inference: 0.0775 s/iter. Eval: 0.0001 s/iter. Total: 0.0785 s/iter. ETA=0:03:13\n",
      "\u001b[32m[04/07 22:50:00 d2.evaluation.evaluator]: \u001b[0mInference done 716/3116. Dataloading: 0.0008 s/iter. Inference: 0.0776 s/iter. Eval: 0.0001 s/iter. Total: 0.0786 s/iter. ETA=0:03:08\n",
      "\u001b[32m[04/07 22:50:05 d2.evaluation.evaluator]: \u001b[0mInference done 779/3116. Dataloading: 0.0008 s/iter. Inference: 0.0777 s/iter. Eval: 0.0001 s/iter. Total: 0.0786 s/iter. ETA=0:03:03\n",
      "\u001b[32m[04/07 22:50:10 d2.evaluation.evaluator]: \u001b[0mInference done 842/3116. Dataloading: 0.0009 s/iter. Inference: 0.0777 s/iter. Eval: 0.0001 s/iter. Total: 0.0787 s/iter. ETA=0:02:58\n",
      "\u001b[32m[04/07 22:50:15 d2.evaluation.evaluator]: \u001b[0mInference done 906/3116. Dataloading: 0.0009 s/iter. Inference: 0.0777 s/iter. Eval: 0.0001 s/iter. Total: 0.0787 s/iter. ETA=0:02:53\n",
      "\u001b[32m[04/07 22:50:20 d2.evaluation.evaluator]: \u001b[0mInference done 970/3116. Dataloading: 0.0008 s/iter. Inference: 0.0777 s/iter. Eval: 0.0001 s/iter. Total: 0.0787 s/iter. ETA=0:02:48\n",
      "\u001b[32m[04/07 22:50:25 d2.evaluation.evaluator]: \u001b[0mInference done 1034/3116. Dataloading: 0.0008 s/iter. Inference: 0.0777 s/iter. Eval: 0.0001 s/iter. Total: 0.0787 s/iter. ETA=0:02:43\n",
      "\u001b[32m[04/07 22:50:30 d2.evaluation.evaluator]: \u001b[0mInference done 1097/3116. Dataloading: 0.0008 s/iter. Inference: 0.0778 s/iter. Eval: 0.0001 s/iter. Total: 0.0788 s/iter. ETA=0:02:39\n",
      "\u001b[32m[04/07 22:50:35 d2.evaluation.evaluator]: \u001b[0mInference done 1159/3116. Dataloading: 0.0008 s/iter. Inference: 0.0779 s/iter. Eval: 0.0001 s/iter. Total: 0.0789 s/iter. ETA=0:02:34\n",
      "\u001b[32m[04/07 22:50:40 d2.evaluation.evaluator]: \u001b[0mInference done 1222/3116. Dataloading: 0.0008 s/iter. Inference: 0.0780 s/iter. Eval: 0.0001 s/iter. Total: 0.0789 s/iter. ETA=0:02:29\n",
      "\u001b[32m[04/07 22:50:45 d2.evaluation.evaluator]: \u001b[0mInference done 1285/3116. Dataloading: 0.0008 s/iter. Inference: 0.0780 s/iter. Eval: 0.0001 s/iter. Total: 0.0790 s/iter. ETA=0:02:24\n",
      "\u001b[32m[04/07 22:50:50 d2.evaluation.evaluator]: \u001b[0mInference done 1351/3116. Dataloading: 0.0008 s/iter. Inference: 0.0779 s/iter. Eval: 0.0001 s/iter. Total: 0.0789 s/iter. ETA=0:02:19\n",
      "\u001b[32m[04/07 22:50:56 d2.evaluation.evaluator]: \u001b[0mInference done 1417/3116. Dataloading: 0.0008 s/iter. Inference: 0.0778 s/iter. Eval: 0.0001 s/iter. Total: 0.0788 s/iter. ETA=0:02:13\n",
      "\u001b[32m[04/07 22:51:01 d2.evaluation.evaluator]: \u001b[0mInference done 1483/3116. Dataloading: 0.0008 s/iter. Inference: 0.0777 s/iter. Eval: 0.0001 s/iter. Total: 0.0786 s/iter. ETA=0:02:08\n",
      "\u001b[32m[04/07 22:51:06 d2.evaluation.evaluator]: \u001b[0mInference done 1544/3116. Dataloading: 0.0008 s/iter. Inference: 0.0778 s/iter. Eval: 0.0001 s/iter. Total: 0.0788 s/iter. ETA=0:02:03\n",
      "\u001b[32m[04/07 22:51:11 d2.evaluation.evaluator]: \u001b[0mInference done 1604/3116. Dataloading: 0.0008 s/iter. Inference: 0.0780 s/iter. Eval: 0.0001 s/iter. Total: 0.0790 s/iter. ETA=0:01:59\n",
      "\u001b[32m[04/07 22:51:16 d2.evaluation.evaluator]: \u001b[0mInference done 1666/3116. Dataloading: 0.0008 s/iter. Inference: 0.0781 s/iter. Eval: 0.0001 s/iter. Total: 0.0791 s/iter. ETA=0:01:54\n",
      "\u001b[32m[04/07 22:51:21 d2.evaluation.evaluator]: \u001b[0mInference done 1730/3116. Dataloading: 0.0008 s/iter. Inference: 0.0781 s/iter. Eval: 0.0001 s/iter. Total: 0.0791 s/iter. ETA=0:01:49\n",
      "\u001b[32m[04/07 22:51:26 d2.evaluation.evaluator]: \u001b[0mInference done 1792/3116. Dataloading: 0.0008 s/iter. Inference: 0.0782 s/iter. Eval: 0.0001 s/iter. Total: 0.0791 s/iter. ETA=0:01:44\n",
      "\u001b[32m[04/07 22:51:31 d2.evaluation.evaluator]: \u001b[0mInference done 1850/3116. Dataloading: 0.0008 s/iter. Inference: 0.0784 s/iter. Eval: 0.0001 s/iter. Total: 0.0794 s/iter. ETA=0:01:40\n",
      "\u001b[32m[04/07 22:51:36 d2.evaluation.evaluator]: \u001b[0mInference done 1907/3116. Dataloading: 0.0008 s/iter. Inference: 0.0787 s/iter. Eval: 0.0001 s/iter. Total: 0.0796 s/iter. ETA=0:01:36\n",
      "\u001b[32m[04/07 22:51:41 d2.evaluation.evaluator]: \u001b[0mInference done 1964/3116. Dataloading: 0.0008 s/iter. Inference: 0.0789 s/iter. Eval: 0.0001 s/iter. Total: 0.0799 s/iter. ETA=0:01:32\n",
      "\u001b[32m[04/07 22:51:46 d2.evaluation.evaluator]: \u001b[0mInference done 2022/3116. Dataloading: 0.0008 s/iter. Inference: 0.0791 s/iter. Eval: 0.0001 s/iter. Total: 0.0801 s/iter. ETA=0:01:27\n",
      "\u001b[32m[04/07 22:51:51 d2.evaluation.evaluator]: \u001b[0mInference done 2080/3116. Dataloading: 0.0008 s/iter. Inference: 0.0793 s/iter. Eval: 0.0001 s/iter. Total: 0.0803 s/iter. ETA=0:01:23\n",
      "\u001b[32m[04/07 22:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 2138/3116. Dataloading: 0.0008 s/iter. Inference: 0.0795 s/iter. Eval: 0.0001 s/iter. Total: 0.0805 s/iter. ETA=0:01:18\n",
      "\u001b[32m[04/07 22:52:01 d2.evaluation.evaluator]: \u001b[0mInference done 2198/3116. Dataloading: 0.0008 s/iter. Inference: 0.0796 s/iter. Eval: 0.0001 s/iter. Total: 0.0806 s/iter. ETA=0:01:13\n",
      "\u001b[32m[04/07 22:52:06 d2.evaluation.evaluator]: \u001b[0mInference done 2256/3116. Dataloading: 0.0008 s/iter. Inference: 0.0798 s/iter. Eval: 0.0001 s/iter. Total: 0.0807 s/iter. ETA=0:01:09\n",
      "\u001b[32m[04/07 22:52:11 d2.evaluation.evaluator]: \u001b[0mInference done 2314/3116. Dataloading: 0.0008 s/iter. Inference: 0.0799 s/iter. Eval: 0.0001 s/iter. Total: 0.0809 s/iter. ETA=0:01:04\n",
      "\u001b[32m[04/07 22:52:16 d2.evaluation.evaluator]: \u001b[0mInference done 2372/3116. Dataloading: 0.0008 s/iter. Inference: 0.0801 s/iter. Eval: 0.0001 s/iter. Total: 0.0811 s/iter. ETA=0:01:00\n",
      "\u001b[32m[04/07 22:52:21 d2.evaluation.evaluator]: \u001b[0mInference done 2430/3116. Dataloading: 0.0008 s/iter. Inference: 0.0802 s/iter. Eval: 0.0001 s/iter. Total: 0.0812 s/iter. ETA=0:00:55\n",
      "\u001b[32m[04/07 22:52:26 d2.evaluation.evaluator]: \u001b[0mInference done 2488/3116. Dataloading: 0.0008 s/iter. Inference: 0.0803 s/iter. Eval: 0.0001 s/iter. Total: 0.0813 s/iter. ETA=0:00:51\n",
      "\u001b[32m[04/07 22:52:31 d2.evaluation.evaluator]: \u001b[0mInference done 2549/3116. Dataloading: 0.0008 s/iter. Inference: 0.0804 s/iter. Eval: 0.0001 s/iter. Total: 0.0813 s/iter. ETA=0:00:46\n",
      "\u001b[32m[04/07 22:52:36 d2.evaluation.evaluator]: \u001b[0mInference done 2608/3116. Dataloading: 0.0008 s/iter. Inference: 0.0805 s/iter. Eval: 0.0001 s/iter. Total: 0.0814 s/iter. ETA=0:00:41\n",
      "\u001b[32m[04/07 22:52:41 d2.evaluation.evaluator]: \u001b[0mInference done 2662/3116. Dataloading: 0.0008 s/iter. Inference: 0.0807 s/iter. Eval: 0.0001 s/iter. Total: 0.0817 s/iter. ETA=0:00:37\n",
      "\u001b[32m[04/07 22:52:46 d2.evaluation.evaluator]: \u001b[0mInference done 2719/3116. Dataloading: 0.0008 s/iter. Inference: 0.0808 s/iter. Eval: 0.0001 s/iter. Total: 0.0818 s/iter. ETA=0:00:32\n",
      "\u001b[32m[04/07 22:52:51 d2.evaluation.evaluator]: \u001b[0mInference done 2776/3116. Dataloading: 0.0008 s/iter. Inference: 0.0810 s/iter. Eval: 0.0001 s/iter. Total: 0.0820 s/iter. ETA=0:00:27\n",
      "\u001b[32m[04/07 22:52:56 d2.evaluation.evaluator]: \u001b[0mInference done 2833/3116. Dataloading: 0.0008 s/iter. Inference: 0.0811 s/iter. Eval: 0.0001 s/iter. Total: 0.0821 s/iter. ETA=0:00:23\n",
      "\u001b[32m[04/07 22:53:01 d2.evaluation.evaluator]: \u001b[0mInference done 2896/3116. Dataloading: 0.0008 s/iter. Inference: 0.0811 s/iter. Eval: 0.0001 s/iter. Total: 0.0820 s/iter. ETA=0:00:18\n",
      "\u001b[32m[04/07 22:53:07 d2.evaluation.evaluator]: \u001b[0mInference done 2956/3116. Dataloading: 0.0008 s/iter. Inference: 0.0811 s/iter. Eval: 0.0001 s/iter. Total: 0.0821 s/iter. ETA=0:00:13\n",
      "\u001b[32m[04/07 22:53:12 d2.evaluation.evaluator]: \u001b[0mInference done 3016/3116. Dataloading: 0.0008 s/iter. Inference: 0.0811 s/iter. Eval: 0.0001 s/iter. Total: 0.0821 s/iter. ETA=0:00:08\n",
      "\u001b[32m[04/07 22:53:17 d2.evaluation.evaluator]: \u001b[0mInference done 3078/3116. Dataloading: 0.0008 s/iter. Inference: 0.0811 s/iter. Eval: 0.0001 s/iter. Total: 0.0821 s/iter. ETA=0:00:03\n",
      "\u001b[32m[04/07 22:53:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:15.382623 (0.082090 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/07 22:53:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:12 (0.081095 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/07 22:53:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/07 22:53:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[04/07 22:53:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/07 22:53:20 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/07 22:53:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[04/07 22:53:20 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/07 22:53:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.041\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.043\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.059\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.080\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.121\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.121\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.123\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.092\n",
      "\u001b[32m[04/07 22:53:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 4.087 | 19.534 | 0.103  | 4.321 | 5.873 | 4.370 |\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"my_dataset_test\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_test\")\n",
    " \n",
    "result = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "\n",
    "# for name, value in result['bbox'].items():\n",
    "#     logger.report_single_value(name=f\"test_{name}\",value=value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 4.086634071732409,\n",
       "               'AP50': 19.534415589701386,\n",
       "               'AP75': 0.10334012124616718,\n",
       "               'APs': 4.3205221332592725,\n",
       "               'APm': 5.873064462443072,\n",
       "               'APl': 4.369740454518531})])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "paths = glob.glob(\"/home/vlad/datasets/drons_vs_berds/images/*/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5857"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "int(random.random()*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/30 17:58:23 d2.data.datasets.coco]: \u001b[0mLoaded 7805 images in COCO format from /home/vlad/datasets/drons_vs_berds/coco/dataset/drons_vs_berds_valid.json\n",
      "\u001b[32m[04/30 17:58:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/30 17:58:23 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/30 17:58:23 d2.data.common]: \u001b[0mSerializing 7805 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 17:58:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.92 MiB\n"
     ]
    }
   ],
   "source": [
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00_06_10_to_00_06_27'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(val_loader))[0]['file_name'].split('/')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m out \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mdraw_instance_predictions(outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstances\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      8\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_save, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(row[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(img_path, \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/berds_vs_drons/lib/python3.11/site-packages/detectron2/utils/visualizer.py:328\u001b[0m, in \u001b[0;36mVisImage.get_image\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m img_rgba \u001b[38;5;241m=\u001b[39m buffer\u001b[38;5;241m.\u001b[39mreshape(height, width, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    327\u001b[0m rgb, alpha \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msplit(img_rgba, [\u001b[38;5;241m3\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rgb\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path_save = '/home/vlad/projects/drons_vs_berds/train/detection2/valid_predicted/'\n",
    "\n",
    "for row in val_loader:\n",
    "    im = cv2.imread(row[0]['file_name'])\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    img_path = os.path.join(path_save, f\"{row[0]['file_name'].split('/')[-2]}_{os.path.basename(row[0]['file_name'])}\")\n",
    "    cv2.imwrite(img_path, out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "    # Save the configuration to a config.yaml file\n",
    "config_yaml_path = \"output/myConfig.yaml\"\n",
    "with open(config_yaml_path, 'w') as file:\n",
    "    yaml.dump(cfg, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instances': Instances(num_instances=13, image_height=2160, image_width=3840, fields=[pred_boxes: Boxes(tensor([[   0.0000,    0.0000,  947.6676,  878.7064],\n",
       "         [   0.0000,    0.0000, 1880.0162,  862.1476],\n",
       "         [ 312.2399,    0.0000, 3132.5972,  850.6199],\n",
       "         [1375.0640,    0.0000, 3840.0000,  848.4592],\n",
       "         [2616.6394,    0.0000, 3840.0000,  848.7403],\n",
       "         [3243.2583,    0.0000, 3840.0000,  868.5027],\n",
       "         [3784.4607,    0.0000, 3840.0000,  874.7025],\n",
       "         [ 785.5020,    0.0000, 3605.8704, 1273.0992],\n",
       "         [3511.4888,    0.0000, 3840.0000, 1321.7504],\n",
       "         [   0.0000,    0.0000, 1841.7069, 1756.2111],\n",
       "         [1837.1652,    0.0000, 3840.0000, 1734.8438],\n",
       "         [2953.6809,    0.0000, 3840.0000, 1743.2695],\n",
       "         [   0.0000,    0.0000, 3504.6045, 2160.0000]], device='cuda:0')), scores: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'), pred_classes: tensor([74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74], device='cuda:0'), pred_masks: tensor([[[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       " \n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       " \n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       " \n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       " \n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]]], device='cuda:0')])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': nan,\n",
       "               'AP50': nan,\n",
       "               'AP75': nan,\n",
       "               'APs': nan,\n",
       "               'APm': nan,\n",
       "               'APl': nan})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"my_dataset_val\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_val\")\n",
    " \n",
    "result = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "\n",
    "for name, value in result['bbox'].items():\n",
    "    logger.report_single_value(name=f\"val_{name}\",value=value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DefaultTrainer.test() missing 1 required positional argument: 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: DefaultTrainer.test() missing 1 required positional argument: 'model'"
     ]
    }
   ],
   "source": [
    "trainer.test(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"/home/vlad/projects/drons_vs_berds/train/detection2/output/model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.3\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading config /home/vlad/projects/drons_vs_berds/train/detection2/output/myConfig.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/07 22:46:45 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /home/vlad/projects/drons_vs_berds/train/detection2/output/model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "\n",
    "cfg.merge_from_file('/home/vlad/projects/drons_vs_berds/train/detection2/output/myConfig.yaml')\n",
    "\n",
    " \n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  \n",
    " \n",
    "cfg.MODEL.WEIGHTS = '/home/vlad/projects/drons_vs_berds/train/detection2/output/model_final.pth'\n",
    "predictor = DefaultPredictor(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_videos=[\n",
    "    \"00_06_10_to_00_06_27\",\n",
    "    \"2019_08_19_GP015869_1520_inspire\" ,\n",
    "    \"GOPR5843_002\",\n",
    "    \"dji_phantom_4_mountain_hover\",\n",
    "    \"gopro_002\",\n",
    "    \"parrot_disco_zoomin_zoomout\",\n",
    "    \"two_distant_phantom\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob('/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0184.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0000.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0008.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0296.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0414.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0396.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0422.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0104.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0244.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0258.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0018.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0338.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0378.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0050.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0138.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0174.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0256.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0044.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0042.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0108.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0084.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0130.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0192.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0392.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0074.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0056.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0170.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0118.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0052.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0278.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0324.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0196.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0238.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0190.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0302.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0336.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0022.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0234.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0116.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0314.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0014.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0114.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0202.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0268.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0270.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0272.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0364.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0102.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0326.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0006.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0282.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0158.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0368.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0332.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0090.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0348.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0070.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0176.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0120.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0416.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0274.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0100.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0308.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0354.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0252.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0220.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0232.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0016.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0228.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0350.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0054.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0036.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0394.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0222.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0012.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0186.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0322.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0226.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0134.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0152.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0024.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0254.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0062.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0408.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0194.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0216.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0404.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0280.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0400.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0172.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0410.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0148.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0124.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0126.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0156.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0198.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0094.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0146.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0032.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0248.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0132.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0082.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0010.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0360.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0160.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0362.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0310.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0128.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0086.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0048.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0076.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0182.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0068.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0164.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0212.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0242.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0316.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0250.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0402.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0178.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0162.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0028.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0398.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0208.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0312.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0306.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0304.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0356.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0300.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0092.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0066.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0240.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0260.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0106.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0218.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0210.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0166.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0140.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0376.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0358.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0342.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0060.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0204.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0262.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0088.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0230.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0038.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0318.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0406.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0374.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0390.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0206.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0098.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0288.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0112.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0072.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0334.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0080.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0144.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0040.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0328.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0046.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0290.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0026.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0292.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0284.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0168.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0418.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0420.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0020.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0330.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0388.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0344.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0136.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0188.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0412.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0200.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0224.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0352.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0154.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0266.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0384.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0002.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0110.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0294.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0058.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0078.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0276.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0236.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0286.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0386.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0096.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0180.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0214.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0340.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0246.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0380.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0064.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0370.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0004.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0030.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0150.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0382.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0320.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0122.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0298.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0034.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0264.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0142.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0346.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0366.jpg',\n",
       " '/home/vlad/datasets/drons_vs_berds/images/GOPR5843_002/0372.jpg']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = cv2.imread(paths[-80])\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2.imwrite('./img.jpg', out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Instances(num_instances=1, image_height=1080, image_width=1920, fields=[pred_boxes: Boxes(tensor([[1059.5670,  543.9017, 1123.1814,  600.6081]], device='cuda:0')), scores: tensor([0.9905], device='cuda:0'), pred_classes: tensor([0], device='cuda:0')])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"instances\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berds_vs_drons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
