{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_coco(model, coco_json, image_dir, coco_save_path ):\n",
    " \n",
    "  with open(coco_json) as f:\n",
    "      data = json.load(f)\n",
    "  coco_predicts = []\n",
    "  for image in tqdm(data['images']):\n",
    "      path_to_image = os.path.join(image_dir, image['file_name'])\n",
    "      result = model.predict(path_to_image,iou=0.2,  verbose=False)[0]\n",
    "      for index, boxe in enumerate(result.boxes):\n",
    "        x1,y1,x2,y2 = tuple(boxe.xyxy.cpu().numpy()[0].tolist())\n",
    "        coco_predicts.append({'image_id': image['id'], 'category_id': 1, 'bbox': [x1,y1,x2-x1,y2-y1], 'score': float(result.boxes.conf[index].cpu())})\n",
    "\n",
    "  with open(coco_save_path, \"w\") as file:\n",
    "      file.write(json.dumps(coco_predicts)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3116/3116 [01:53<00:00, 27.38it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_coco(\n",
    "    model=YOLO(f'/home/vlad/projects/drons_vs_berds/prediction/yolo/models/yolo8m_best.pt'),\n",
    "    coco_json = \"/home/vlad/datasets/drons_vs_berds/coco/dataset/drons_vs_berds_test.json\",\n",
    "    image_dir = \"/home/vlad/datasets/drons_vs_berds/images\",\n",
    "    coco_save_path= '/home/vlad/projects/drons_vs_berds/prediction/yolo/results/yolo8m_best.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3116/3116 [00:59<00:00, 52.30it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_coco(\n",
    "    model=YOLO(f'/home/vlad/projects/drons_vs_berds/prediction/yolo/models/yolo8n_best.pt'),\n",
    "    coco_json = \"/home/vlad/datasets/drons_vs_berds/coco/dataset/drons_vs_berds_test.json\",\n",
    "    image_dir = \"/home/vlad/datasets/drons_vs_berds/images\",\n",
    "    coco_save_path= '/home/vlad/projects/drons_vs_berds/prediction/yolo/results/yolo8n_best.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing coco dataset annotations...\n",
      "Loading coco annotations: 100%|██████████| 3116/3116 [00:00<00:00, 16349.61it/s]\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Progress of predictions:   7%|█              | 222/3116 [00:40<08:50,  5.46it/s]^C\n",
      "Progress of predictions:   7%|█              | 222/3116 [00:40<08:54,  5.42it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vlad/projects/drons_vs_berds/prediction/yolo/../evaluate_sahi.py\", line 142, in <module>\n",
      "    metrics = evaluator.evaluate()\n",
      "              ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vlad/projects/drons_vs_berds/prediction/yolo/../evaluate_sahi.py\", line 77, in evaluate\n",
      "    prediction_result = get_sliced_prediction(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vlad/anaconda3/envs/berds_vs_drons/lib/python3.11/site-packages/sahi/predict.py\", line 241, in get_sliced_prediction\n",
      "    prediction_result = get_prediction(\n",
      "                        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/vlad/anaconda3/envs/berds_vs_drons/lib/python3.11/site-packages/sahi/predict.py\", line 93, in get_prediction\n",
      "    detection_model.perform_inference(np.ascontiguousarray(image_as_pil))\n",
      "  File \"/home/vlad/anaconda3/envs/berds_vs_drons/lib/python3.11/site-packages/sahi/models/yolov8.py\", line 61, in perform_inference\n",
      "    prediction_result = self.model(image[:, :, ::-1], verbose=False)  # YOLOv8 expects numpy arrays to have BGR\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vlad/anaconda3/envs/berds_vs_drons/lib/python3.11/site-packages/ultralytics/engine/model.py\", line 155, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vlad/anaconda3/envs/berds_vs_drons/lib/python3.11/site-packages/ultralytics/engine/model.py\", line 406, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "                                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vlad/anaconda3/envs/berds_vs_drons/lib/python3.11/site-packages/ultralytics/engine/predictor.py\", line 204, in __call__\n",
      "    return list(self.stream_inference(source, model, *args, **kwargs))  # merge list of Result into one\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vlad/anaconda3/envs/berds_vs_drons/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"/home/vlad/anaconda3/envs/berds_vs_drons/lib/python3.11/site-packages/ultralytics/engine/predictor.py\", line 279, in stream_inference\n",
      "    im = self.preprocess(im0s)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vlad/anaconda3/envs/berds_vs_drons/lib/python3.11/site-packages/ultralytics/engine/predictor.py\", line 127, in preprocess\n",
      "    im = im.to(self.device)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../evaluate_sahi.py --model_path \"/home/vlad/projects/drons_vs_berds/prediction/yolo/models/yolo8n_slice_640.pt\" --coco_json \"/home/vlad/datasets/drons_vs_berds/coco/dataset/drons_vs_berds_test.json\" --image_dir \"/home/vlad/datasets/drons_vs_berds/images\" --save_path='/home/vlad/projects/drons_vs_berds/prediction/yolo/results/yolo8n_slice_640_sahi.json' --slice_size=640 --model_type='yolov8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../evaluate_sahi.py --model_path \"/home/vlad/projects/drons_vs_berds/prediction/yolo/models/yolo8n_best.pt\" --coco_json \"/home/vlad/datasets/drons_vs_berds/coco/dataset/drons_vs_berds_test.json\" --image_dir \"/home/vlad/datasets/drons_vs_berds/images\" --save_path='/home/vlad/projects/drons_vs_berds/prediction/yolo/results/yolo8n_best_sahi_640.json' --slice_size=640 --model_type='yolov8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../evaluate_sahi.py --model_path \"/home/vlad/projects/drons_vs_berds/prediction/yolo/models/yolo8n_best.pt\" --coco_json \"/home/vlad/datasets/drons_vs_berds/coco/dataset/drons_vs_berds_test.json\" --image_dir \"/home/vlad/datasets/drons_vs_berds/images\" --save_path='/home/vlad/projects/drons_vs_berds/prediction/yolo/results/yolo8n_best_sahi_1024.json' --slice_size=1024 --model_type='yolov8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berds_vs_drons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
